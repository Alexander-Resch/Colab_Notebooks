{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet50_CifarTest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alexander-Resch/Colab_Notebooks/blob/main/ResNet50_CifarMnistTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSCgqp1QdP2e",
        "outputId": "de18e3b4-9e7b-4987-bd4d-7cd306677ef6"
      },
      "source": [
        "import pandas as pd \r\n",
        "import math\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import keras\r\n",
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "#from keras.backend.tensorflow_backend import set_session\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, \\\r\n",
        "    AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\r\n",
        "from keras.initializers import glorot_uniform\r\n",
        "from keras.models import Model, load_model\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "import keras.backend as K\r\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, LearningRateScheduler\r\n",
        "\r\n",
        "K.set_image_data_format('channels_last')\r\n",
        "K.set_learning_phase(1)\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import torch\r\n",
        "torch.cuda.get_device_name()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbHTJkAXdYT7"
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\r\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\r\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\r\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\r\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # defining name basis\r\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\r\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\r\n",
        "\r\n",
        "    # Retrieve Filters\r\n",
        "    F1, F2, F3 = filters\r\n",
        "\r\n",
        "    # Save the input value. You'll need this later to add back to the main path.\r\n",
        "    X_shortcut = X\r\n",
        "\r\n",
        "    # First component of main path\r\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a',\r\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\r\n",
        "    X = Activation('relu')(X)\r\n",
        "\r\n",
        "    # Second component of main path \r\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b',\r\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\r\n",
        "    X = Activation('relu')(X)\r\n",
        "\r\n",
        "    # Third component of main path \r\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c',\r\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\r\n",
        "\r\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \r\n",
        "    X = Add()([X, X_shortcut])\r\n",
        "    X = Activation('relu')(X)\r\n",
        "\r\n",
        "    return X\r\n",
        "\r\n",
        "\r\n",
        "def convolutional_block(X, f, filters, stage, block, s=2):\r\n",
        "    \"\"\"\r\n",
        "    Implementation of the convolutional block as defined in Figure 4\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\r\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\r\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\r\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\r\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\r\n",
        "    s -- Integer, specifying the stride to be used\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # defining name basis\r\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\r\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\r\n",
        "\r\n",
        "    # Retrieve Filters\r\n",
        "    F1, F2, F3 = filters\r\n",
        "\r\n",
        "    # Save the input value\r\n",
        "    X_shortcut = X\r\n",
        "\r\n",
        "    # First component of main path\r\n",
        "    X = Conv2D(F1, (1, 1), strides=(s, s), name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\r\n",
        "    X = Activation('relu')(X)\r\n",
        "\r\n",
        "\r\n",
        "    # Second component of main path \r\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b',\r\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\r\n",
        "    X = Activation('relu')(X)\r\n",
        "\r\n",
        "    # Third component of main path\r\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c',\r\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\r\n",
        "\r\n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1',\r\n",
        "                        kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\r\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\r\n",
        "\r\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \r\n",
        "    X = Add()([X, X_shortcut])\r\n",
        "    X = Activation('relu')(X)\r\n",
        "\r\n",
        "\r\n",
        "    return X\r\n",
        "\r\n",
        "\r\n",
        "def ResNet50(input_shape=(32, 32, 1), classes=10):\r\n",
        "    \"\"\"\r\n",
        "    Implementation of the popular ResNet50 the following architecture:\r\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\r\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    input_shape -- shape of the images of the dataset\r\n",
        "    classes -- integer, number of classes\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    model -- a Model() instance in Keras\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # Define the input as a tensor with shape input_shape\r\n",
        "    X_input = Input(input_shape)\r\n",
        "\r\n",
        "    # Zero-Padding\r\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\r\n",
        "\r\n",
        "    # Stage 1\r\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\r\n",
        "    X = Activation('relu')(X)\r\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\r\n",
        "\r\n",
        "    # Stage 2\r\n",
        "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\r\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\r\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\r\n",
        "\r\n",
        "\r\n",
        "    # Stage 3\r\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\r\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\r\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\r\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\r\n",
        "\r\n",
        "    '''\r\n",
        "    # Stage 4 \r\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\r\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\r\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\r\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\r\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\r\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\r\n",
        "    \r\n",
        "    # Stage 5 \r\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='5a', s = 2)\r\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\r\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\r\n",
        "\r\n",
        "    '''\r\n",
        "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\r\n",
        "\r\n",
        "\r\n",
        "    # output layer\r\n",
        "    X = Flatten()(X)\r\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\r\n",
        "\r\n",
        "    # Create model\r\n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\r\n",
        "\r\n",
        "    return model "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecMgmaluYUK4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa46450f-5a02-48a9-96a4-ebc4413fb287"
      },
      "source": [
        "def truncate_images(X):\r\n",
        "  return X[:,2:-2,2:-2,:]\r\n",
        "\r\n",
        "\r\n",
        "#(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\r\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\r\n",
        "\r\n",
        "X_train = X_train.astype('float32')\r\n",
        "X_test = X_test.astype('float32')\r\n",
        "X_train = X_train / 255.0\r\n",
        "X_test = X_test / 255.0\r\n",
        "\r\n",
        "def grayscale(data, dtype='float32'):\r\n",
        "    # luma coding weighted average in video systems\r\n",
        "    #print(data.shape)\r\n",
        "    if data.shape[-1] != 3:\r\n",
        "      return data.reshape(data.shape[0],data.shape[1],data.shape[2],1)\r\n",
        "    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)\r\n",
        "    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\r\n",
        "    # add channel dimension\r\n",
        "    rst = np.expand_dims(rst, axis=3)\r\n",
        "    return rst\r\n",
        "\r\n",
        "\r\n",
        "X_train_gray = grayscale(X_train)\r\n",
        "X_test_gray = grayscale(X_test)\r\n",
        "\r\n",
        "from keras.utils import np_utils\r\n",
        "y_train = np_utils.to_categorical(y_train, 10)\r\n",
        "y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp5WwOeIaS1M",
        "outputId": "d42b95c8-9dff-4eed-b407-51fc854afdad"
      },
      "source": [
        "# define constants\r\n",
        "batch_size = 512\r\n",
        "epoch_max = 100\r\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1)\r\n",
        "#input_shape = (28,28,1) for mnist, and (32,32,1), which is default, for cifar\r\n",
        "input_shape = (28,28,1)\r\n",
        "model = ResNet50(input_shape)\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\r\n",
        "model.summary()\r\n",
        "#print('Total number of parameters: {}'.format(model.count_params()))\r\n",
        "\r\n",
        "datagen = ImageDataGenerator(rotation_range=20, \\\r\n",
        "                             width_shift_range=0.1, \\\r\n",
        "                             height_shift_range=0.1, \\\r\n",
        "                             shear_range=0.1, \\\r\n",
        "                             zoom_range=0.2, \\\r\n",
        "                             horizontal_flip=True, \\\r\n",
        "                             fill_mode='nearest')\r\n",
        "\r\n",
        "def fit(model):\r\n",
        "    hist = model.fit(\r\n",
        "                    #datagen.flow(X_train_gray, y_train, batch_size=batch_size),  \\\r\n",
        "                    X_train_gray, y_train,\r\n",
        "                    batch_size=batch_size, \\\r\n",
        "                    epochs=epoch_max, \\\r\n",
        "                    validation_data=(X_test_gray, y_test), \\\r\n",
        "                    callbacks=[early_stop], \\\r\n",
        "                    shuffle=True, verbose=1)\r\n",
        "    return hist\r\n",
        "hist = fit(model)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, 34, 34, 1)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 14, 14, 64)   3200        zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 14, 14, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 14, 14, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 64)     0           activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 6, 6, 64)     4160        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 6, 6, 64)     256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 6, 6, 64)     0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 6, 6, 64)     36928       activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 6, 6, 64)     256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 6, 6, 64)     0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 6, 6, 256)    16640       activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 6, 6, 256)    16640       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 6, 6, 256)    1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 6, 6, 256)    1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 6, 6, 256)    0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 6, 6, 256)    0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 6, 6, 64)     16448       activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 6, 6, 64)     256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 6, 6, 64)     0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 6, 6, 64)     36928       activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 6, 6, 64)     256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 6, 6, 64)     0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 6, 6, 256)    16640       activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 6, 6, 256)    1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 6, 6, 256)    0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 6, 6, 256)    0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 6, 6, 64)     16448       activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 6, 6, 64)     256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 6, 6, 64)     0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 6, 6, 64)     36928       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 6, 6, 64)     256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 6, 6, 64)     0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 6, 6, 256)    16640       activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 6, 6, 256)    1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 6, 6, 256)    0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 6, 6, 256)    0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 3, 3, 128)    32896       activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 3, 3, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 3, 3, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 3, 3, 128)    147584      activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 3, 3, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 3, 3, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 3, 3, 512)    66048       activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 3, 3, 512)    131584      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 3, 3, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 3, 3, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 3, 3, 512)    0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 3, 3, 512)    0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 3, 3, 128)    65664       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 3, 3, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 3, 3, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 3, 3, 128)    147584      activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 3, 3, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 3, 3, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 3, 3, 512)    66048       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 3, 3, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 3, 3, 512)    0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 3, 3, 512)    0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 3, 3, 128)    65664       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 3, 3, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 3, 3, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 3, 3, 128)    147584      activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 3, 3, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 3, 3, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 3, 3, 512)    66048       activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 3, 3, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 3, 3, 512)    0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 3, 3, 512)    0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 3, 3, 128)    65664       activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 3, 3, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 3, 3, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 3, 3, 128)    147584      activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 3, 3, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 3, 3, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 3, 3, 512)    66048       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 3, 3, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 3, 3, 512)    0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 3, 3, 512)    0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 512)    0           activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 512)          0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc10 (Dense)                    (None, 10)           5130        flatten_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,458,954\n",
            "Trainable params: 1,448,842\n",
            "Non-trainable params: 10,112\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "118/118 [==============================] - 11s 74ms/step - loss: 0.6705 - accuracy: 0.8251 - val_loss: 2.5235 - val_accuracy: 0.0982\n",
            "Epoch 2/100\n",
            "118/118 [==============================] - 8s 70ms/step - loss: 0.0398 - accuracy: 0.9878 - val_loss: 2.7711 - val_accuracy: 0.1551\n",
            "Epoch 3/100\n",
            "118/118 [==============================] - 8s 70ms/step - loss: 0.0281 - accuracy: 0.9908 - val_loss: 2.9906 - val_accuracy: 0.2202\n",
            "Epoch 4/100\n",
            "118/118 [==============================] - 8s 70ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.3066 - val_accuracy: 0.9035\n",
            "Epoch 5/100\n",
            "118/118 [==============================] - 8s 71ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.1027 - val_accuracy: 0.9722\n",
            "Epoch 6/100\n",
            "118/118 [==============================] - 8s 70ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.0429 - val_accuracy: 0.9874\n",
            "Epoch 7/100\n",
            "118/118 [==============================] - 8s 70ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.0547 - val_accuracy: 0.9851\n",
            "Epoch 8/100\n",
            "118/118 [==============================] - 8s 70ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0761 - val_accuracy: 0.9818\n",
            "Epoch 9/100\n",
            "118/118 [==============================] - 8s 70ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0553 - val_accuracy: 0.9863\n",
            "Epoch 10/100\n",
            "118/118 [==============================] - 8s 71ms/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 0.0541 - val_accuracy: 0.9849\n",
            "Epoch 11/100\n",
            "118/118 [==============================] - 8s 70ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0327 - val_accuracy: 0.9914\n",
            "Epoch 12/100\n",
            "118/118 [==============================] - 8s 70ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0315 - val_accuracy: 0.9917\n",
            "Epoch 13/100\n",
            "118/118 [==============================] - 8s 70ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1193 - val_accuracy: 0.9711\n",
            "Epoch 14/100\n",
            "118/118 [==============================] - 8s 69ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0876 - val_accuracy: 0.9800\n",
            "Epoch 15/100\n",
            "118/118 [==============================] - 8s 69ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0614 - val_accuracy: 0.9854\n",
            "Epoch 16/100\n",
            "118/118 [==============================] - 8s 69ms/step - loss: 0.0050 - accuracy: 0.9981 - val_loss: 0.1023 - val_accuracy: 0.9807\n",
            "Epoch 17/100\n",
            "118/118 [==============================] - 8s 69ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.0383 - val_accuracy: 0.9907\n",
            "Epoch 00017: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d34syWddcRaE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "0adc1238-b7a2-48a3-c136-27fe5661f9c8"
      },
      "source": [
        "f = plt.figure(figsize=(14,10))\r\n",
        "ax = f.add_subplot()\r\n",
        "epochs = range(1,hist.epoch[-1]+2)\r\n",
        "acc_train = hist.history['accuracy']\r\n",
        "acc_val = hist.history['val_accuracy']\r\n",
        "\r\n",
        "ax.scatter(epochs,acc_train, label='Training Accuracy')\r\n",
        "ax.scatter(epochs,acc_val, label='Validation Accuracy')\r\n",
        "\r\n",
        "ax.legend()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5613b71d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vzbUlz7Tvj_",
        "outputId": "37c306be-37b0-4651-8ff0-3713544de309",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hist.epoch"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm-jL4xIRUww"
      },
      "source": [
        "model.count_params()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
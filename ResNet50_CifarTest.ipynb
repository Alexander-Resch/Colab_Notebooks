{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet50_CifarTest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alexander-Resch/Colab_Notebooks/blob/main/ResNet50_CifarTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSCgqp1QdP2e",
        "outputId": "36db4af6-8df9-4f57-b116-cb3f1f9c4573"
      },
      "source": [
        "import pandas as pd \r\n",
        "import math\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import keras\r\n",
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "#from keras.backend.tensorflow_backend import set_session\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, \\\r\n",
        "    AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\r\n",
        "from keras.initializers import glorot_uniform\r\n",
        "from keras.models import Model, load_model\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "import keras.backend as K\r\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, LearningRateScheduler\r\n",
        "\r\n",
        "K.set_image_data_format('channels_last')\r\n",
        "K.set_learning_phase(1)\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbHTJkAXdYT7"
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\r\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\r\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\r\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\r\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # defining name basis\r\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\r\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\r\n",
        "\r\n",
        "    # Retrieve Filters\r\n",
        "    F1, F2, F3 = filters\r\n",
        "\r\n",
        "    # Save the input value. You'll need this later to add back to the main path.\r\n",
        "    X_shortcut = X\r\n",
        "\r\n",
        "    # First component of main path\r\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a',\r\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\r\n",
        "    X = Activation('relu')(X)\r\n",
        "\r\n",
        "    # Second component of main path \r\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b',\r\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\r\n",
        "    X = Activation('relu')(X)\r\n",
        "\r\n",
        "    # Third component of main path \r\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c',\r\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\r\n",
        "\r\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \r\n",
        "    X = Add()([X, X_shortcut])\r\n",
        "    X = Activation('relu')(X)\r\n",
        "\r\n",
        "    return X\r\n",
        "\r\n",
        "\r\n",
        "def convolutional_block(X, f, filters, stage, block, s=2):\r\n",
        "    \"\"\"\r\n",
        "    Implementation of the convolutional block as defined in Figure 4\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\r\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\r\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\r\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\r\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\r\n",
        "    s -- Integer, specifying the stride to be used\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # defining name basis\r\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\r\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\r\n",
        "\r\n",
        "    # Retrieve Filters\r\n",
        "    F1, F2, F3 = filters\r\n",
        "\r\n",
        "    # Save the input value\r\n",
        "    X_shortcut = X\r\n",
        "\r\n",
        "    # First component of main path\r\n",
        "    X = Conv2D(F1, (1, 1), strides=(s, s), name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\r\n",
        "    X = Activation('relu')(X)\r\n",
        "\r\n",
        "\r\n",
        "    # Second component of main path \r\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b',\r\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\r\n",
        "    X = Activation('relu')(X)\r\n",
        "\r\n",
        "    # Third component of main path\r\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c',\r\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\r\n",
        "\r\n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1',\r\n",
        "                        kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\r\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\r\n",
        "\r\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \r\n",
        "    X = Add()([X, X_shortcut])\r\n",
        "    X = Activation('relu')(X)\r\n",
        "\r\n",
        "\r\n",
        "    return X\r\n",
        "\r\n",
        "\r\n",
        "def ResNet50(input_shape=(32, 32, 1), classes=10):\r\n",
        "    \"\"\"\r\n",
        "    Implementation of the popular ResNet50 the following architecture:\r\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\r\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    input_shape -- shape of the images of the dataset\r\n",
        "    classes -- integer, number of classes\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    model -- a Model() instance in Keras\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # Define the input as a tensor with shape input_shape\r\n",
        "    X_input = Input(input_shape)\r\n",
        "\r\n",
        "    # Zero-Padding\r\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\r\n",
        "\r\n",
        "    # Stage 1\r\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\r\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\r\n",
        "    X = Activation('relu')(X)\r\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\r\n",
        "\r\n",
        "    # Stage 2\r\n",
        "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\r\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\r\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\r\n",
        "\r\n",
        "\r\n",
        "    # Stage 3\r\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\r\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\r\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\r\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\r\n",
        "\r\n",
        "    \r\n",
        "    # Stage 4 \r\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\r\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\r\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\r\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\r\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\r\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\r\n",
        "    '''\r\n",
        "    # Stage 5 \r\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='5a', s = 2)\r\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\r\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\r\n",
        "\r\n",
        "    '''\r\n",
        "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\r\n",
        "\r\n",
        "\r\n",
        "    # output layer\r\n",
        "    X = Flatten()(X)\r\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\r\n",
        "\r\n",
        "    # Create model\r\n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\r\n",
        "\r\n",
        "    return model "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecMgmaluYUK4",
        "outputId": "468611d5-df81-4929-854a-a1f6ae1facfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def truncate_images(X):\r\n",
        "  return X[:,2:-2,2:-2,:]\r\n",
        "\r\n",
        "\r\n",
        "#(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\r\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\r\n",
        "\r\n",
        "X_train = X_train.astype('float32')\r\n",
        "X_test = X_test.astype('float32')\r\n",
        "X_train = X_train / 255.0\r\n",
        "X_test = X_test / 255.0\r\n",
        "\r\n",
        "def grayscale(data, dtype='float32'):\r\n",
        "    # luma coding weighted average in video systems\r\n",
        "    print(data.shape)\r\n",
        "    if data.shape[-1] != 3:\r\n",
        "      return data.reshape(data.shape[0],data.shape[1],data.shape[2],1)\r\n",
        "    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)\r\n",
        "    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\r\n",
        "    # add channel dimension\r\n",
        "    rst = np.expand_dims(rst, axis=3)\r\n",
        "    return rst\r\n",
        "\r\n",
        "\r\n",
        "X_train_gray = grayscale(X_train)\r\n",
        "X_test_gray = grayscale(X_test)\r\n",
        "\r\n",
        "from keras.utils import np_utils\r\n",
        "y_train = np_utils.to_categorical(y_train, 10)\r\n",
        "y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp5WwOeIaS1M",
        "outputId": "bd65d878-cde7-4aa8-8e3a-1111c746ab6c"
      },
      "source": [
        "# define constants\r\n",
        "batch_size = 256\r\n",
        "epoch_max = 100\r\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\r\n",
        "#input_shape = (28,28,1) for mnist, and (32,32,1), which is default, for cifar\r\n",
        "input_shape = (28,28,1)\r\n",
        "model = ResNet50(input_shape)\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\r\n",
        "#model.summary()\r\n",
        "\r\n",
        "datagen = ImageDataGenerator(rotation_range=20, \\\r\n",
        "                             width_shift_range=0.1, \\\r\n",
        "                             height_shift_range=0.1, \\\r\n",
        "                             shear_range=0.1, \\\r\n",
        "                             zoom_range=0.2, \\\r\n",
        "                             horizontal_flip=True, \\\r\n",
        "                             fill_mode='nearest')\r\n",
        "\r\n",
        "def fit(model):\r\n",
        "    hist = model.fit(\r\n",
        "                    datagen.flow(X_train_gray, y_train, batch_size=batch_size),  \\\r\n",
        "        \r\n",
        "                    #batch_size=batch_size, \\\r\n",
        "                    epochs=epoch_max, \\\r\n",
        "                    validation_data=(X_test_gray, y_test), \\\r\n",
        "                    callbacks=[early_stop], \\\r\n",
        "                    shuffle=True, verbose=1)\r\n",
        "    return hist\r\n",
        "hist = fit(model)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "235/235 [==============================] - 26s 92ms/step - loss: 1.3679 - accuracy: 0.6385 - val_loss: 2.8025 - val_accuracy: 0.1396\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 21s 88ms/step - loss: 0.2309 - accuracy: 0.9277 - val_loss: 0.2800 - val_accuracy: 0.9151\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 20s 86ms/step - loss: 0.1754 - accuracy: 0.9456 - val_loss: 0.1120 - val_accuracy: 0.9663\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 20s 86ms/step - loss: 0.1336 - accuracy: 0.9582 - val_loss: 0.1570 - val_accuracy: 0.9517\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 20s 87ms/step - loss: 0.1205 - accuracy: 0.9638 - val_loss: 0.0735 - val_accuracy: 0.9750\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 20s 87ms/step - loss: 0.1035 - accuracy: 0.9679 - val_loss: 0.1081 - val_accuracy: 0.9676\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 20s 86ms/step - loss: 0.0983 - accuracy: 0.9688 - val_loss: 0.0939 - val_accuracy: 0.9709\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 20s 86ms/step - loss: 0.0937 - accuracy: 0.9716 - val_loss: 0.0854 - val_accuracy: 0.9724\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 20s 87ms/step - loss: 0.0827 - accuracy: 0.9735 - val_loss: 0.0713 - val_accuracy: 0.9785\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 20s 85ms/step - loss: 0.0831 - accuracy: 0.9748 - val_loss: 0.0713 - val_accuracy: 0.9779\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 20s 85ms/step - loss: 0.0729 - accuracy: 0.9767 - val_loss: 0.0840 - val_accuracy: 0.9743\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 20s 84ms/step - loss: 0.0748 - accuracy: 0.9762 - val_loss: 0.0440 - val_accuracy: 0.9860\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 20s 85ms/step - loss: 0.0731 - accuracy: 0.9769 - val_loss: 0.1150 - val_accuracy: 0.9630\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 20s 84ms/step - loss: 0.0673 - accuracy: 0.9785 - val_loss: 0.0622 - val_accuracy: 0.9801\n",
            "Epoch 15/100\n",
            "235/235 [==============================] - 20s 84ms/step - loss: 0.0693 - accuracy: 0.9786 - val_loss: 2.1778 - val_accuracy: 0.7275\n",
            "Epoch 16/100\n",
            "235/235 [==============================] - 20s 84ms/step - loss: 0.3526 - accuracy: 0.9122 - val_loss: 0.9896 - val_accuracy: 0.9674\n",
            "Epoch 17/100\n",
            "235/235 [==============================] - 20s 84ms/step - loss: 0.1036 - accuracy: 0.9680 - val_loss: 0.0485 - val_accuracy: 0.9847\n",
            "Epoch 18/100\n",
            "235/235 [==============================] - 20s 85ms/step - loss: 0.0838 - accuracy: 0.9737 - val_loss: 0.2545 - val_accuracy: 0.9166\n",
            "Epoch 19/100\n",
            "235/235 [==============================] - 20s 83ms/step - loss: 0.0908 - accuracy: 0.9717 - val_loss: 0.0400 - val_accuracy: 0.9865\n",
            "Epoch 20/100\n",
            "235/235 [==============================] - 20s 83ms/step - loss: 0.0780 - accuracy: 0.9763 - val_loss: 0.0693 - val_accuracy: 0.9798\n",
            "Epoch 21/100\n",
            "235/235 [==============================] - 20s 84ms/step - loss: 0.0706 - accuracy: 0.9777 - val_loss: 0.0465 - val_accuracy: 0.9843\n",
            "Epoch 22/100\n",
            "235/235 [==============================] - 20s 83ms/step - loss: 0.0598 - accuracy: 0.9807 - val_loss: 0.0400 - val_accuracy: 0.9870\n",
            "Epoch 23/100\n",
            "235/235 [==============================] - 20s 84ms/step - loss: 0.0609 - accuracy: 0.9805 - val_loss: 0.0456 - val_accuracy: 0.9846\n",
            "Epoch 24/100\n",
            "235/235 [==============================] - 20s 83ms/step - loss: 0.0560 - accuracy: 0.9820 - val_loss: 0.0405 - val_accuracy: 0.9873\n",
            "Epoch 25/100\n",
            "235/235 [==============================] - 20s 84ms/step - loss: 0.0566 - accuracy: 0.9816 - val_loss: 0.0381 - val_accuracy: 0.9879\n",
            "Epoch 26/100\n",
            "235/235 [==============================] - 20s 83ms/step - loss: 0.0528 - accuracy: 0.9832 - val_loss: 0.0556 - val_accuracy: 0.9815\n",
            "Epoch 27/100\n",
            "235/235 [==============================] - 20s 83ms/step - loss: 0.0545 - accuracy: 0.9824 - val_loss: 0.0493 - val_accuracy: 0.9845\n",
            "Epoch 28/100\n",
            "235/235 [==============================] - 20s 83ms/step - loss: 0.0568 - accuracy: 0.9815 - val_loss: 0.0573 - val_accuracy: 0.9813\n",
            "Epoch 29/100\n",
            "235/235 [==============================] - 20s 84ms/step - loss: 0.0547 - accuracy: 0.9827 - val_loss: 0.0436 - val_accuracy: 0.9872\n",
            "Epoch 30/100\n",
            "235/235 [==============================] - 20s 84ms/step - loss: 0.0534 - accuracy: 0.9836 - val_loss: 0.0403 - val_accuracy: 0.9876\n",
            "Epoch 31/100\n",
            "235/235 [==============================] - 20s 83ms/step - loss: 0.0509 - accuracy: 0.9834 - val_loss: 0.0919 - val_accuracy: 0.9710\n",
            "Epoch 32/100\n",
            "235/235 [==============================] - 20s 83ms/step - loss: 0.0547 - accuracy: 0.9821 - val_loss: 0.0429 - val_accuracy: 0.9856\n",
            "Epoch 33/100\n",
            "235/235 [==============================] - 20s 85ms/step - loss: 0.0513 - accuracy: 0.9830 - val_loss: 0.0552 - val_accuracy: 0.9836\n",
            "Epoch 34/100\n",
            "235/235 [==============================] - 20s 84ms/step - loss: 0.0506 - accuracy: 0.9842 - val_loss: 0.0601 - val_accuracy: 0.9818\n",
            "Epoch 35/100\n",
            "235/235 [==============================] - 20s 83ms/step - loss: 0.0525 - accuracy: 0.9835 - val_loss: 0.0571 - val_accuracy: 0.9835\n",
            "Epoch 00035: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d34syWddcRaE",
        "outputId": "90f504ba-4588-47aa-898f-e253a71f5743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\r\n",
        "torch.cuda.get_device_name()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vzbUlz7Tvj_"
      },
      "source": [
        "hist.history."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}